{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-EXFD2i8jMd"
   },
   "source": [
    "## Classification of VOC 2012 Dataset using VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jolDXtd_Ojkp"
   },
   "source": [
    "**Created:** 04/21/21\n",
    "\n",
    "**Author:** Muqtada Hussain Mohammed\n",
    "\n",
    "**Email:** muqtada.husn@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byLqLddIYrnd"
   },
   "source": [
    "Downloading VOC 2012 dataset (Update the link from http://host.robots.ox.ac.uk:8080/pascal/VOC/voc2012/#data if it is broken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iG1Ldb7ib14z",
    "outputId": "caed96d3-f7c9-400f-89f2-276e8e285e74"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gdown http://host.robots.ox.ac.uk:8080/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "tar -xvf VOCtrainval_11-May-2012.tar > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KI4JvsW-bej"
   },
   "source": [
    "This step is to import necessary libraries for building our neural networks. I have used  Keras primarily to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eb3VbYKPxrdN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from imutils import paths\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE_a2RN5lZI2"
   },
   "source": [
    "Mount Google Drive only if necessary (If you have files stored on google drive which works only on google colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db2MbrRbiKvt",
    "outputId": "3e8671db-86e6-478a-98e7-17e8555bee9f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dkM7fEx5vGI"
   },
   "source": [
    "Loading a pre-trained VGG19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrdqrfUexrdb",
    "outputId": "e944526c-b2b8-4c7a-8fe5-cde2cb92119c"
   },
   "outputs": [],
   "source": [
    "model = VGG19(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqlpW_oy6ShA"
   },
   "source": [
    "Model summary of VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-8CPntW1K_a",
    "outputId": "3d4e9fcf-0954-4fc6-fcd2-b15285f9dc12"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_G1CACa71-1K",
    "outputId": "943e678e-5f44-44fe-b826-2030ca938b42"
   },
   "outputs": [],
   "source": [
    "#Getting second last layer of the model and redefine it according to the VOC2012s class size (20)\n",
    "last_layer = model.layers[-2].output\n",
    "new_model = Dense(20, activation='softmax', name='VOC2012')(last_layer)\n",
    "new_model = Model(model.input, new_model, name='VGG19_VOC2012Classification')\n",
    "\n",
    "#To reduce no of trainable parameters, VGG19 layers must be made non trainable\n",
    "for layer in new_model.layers[:-1]: layer.trainable=False\n",
    "\n",
    "#Compiling the new model\n",
    "new_model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eu31d_mew-n"
   },
   "source": [
    "Initializing data (x), label(y), class and path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iezSKLfSfA6x"
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "classes= {'person':0,'bird':1, 'cat':2, 'cow':3, 'dog':4, 'horse':5, 'sheep':6,'aeroplane':7, 'bicycle':8, 'boat':9, 'bus':10, 'car':11, 'motorbike':12, 'train':13,'bottle':14, 'chair':15, 'diningtable':16, 'pottedplant':17, 'sofa':18, 'tvmonitor':19}\n",
    "pathlist = Path('/content/VOCdevkit/VOC2012/JPEGImages').rglob('*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0NsPYiel265"
   },
   "source": [
    "Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKe2Evx0ijW1",
    "outputId": "911f9fd6-649c-4565-b0c8-b606b048655a"
   },
   "outputs": [],
   "source": [
    "#Loading image data and labels from the given path\n",
    "for p in pathlist:\n",
    "  y_label=np.zeros(20).astype(int)\n",
    "  act_label=set()\n",
    "  img_path=str(p)\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  yhat = model.predict(x)\n",
    "  label = decode_predictions(yhat)\n",
    "  label = label[0][0]\n",
    "\n",
    "#Printing VGG19 predicted label on the raw data since VGG19 is able to classify images into 1000 predefined classes\n",
    "  #print('VGG19 Label: %s (%.2f%%)' % (label[1], label[2]*100))\n",
    "  data.append(x)\n",
    "  lbl_path=str(p).replace('.jpg','.xml').replace('JPEGImages','Annotations')\n",
    "  tree = ET.parse(lbl_path)\n",
    "  root = tree.getroot()\n",
    "  for child in root:\n",
    "      if child.tag=='object':\n",
    "        for subchild in child:\n",
    "          if subchild.tag=='name':\n",
    "            act_label.add(subchild.text)\n",
    "\n",
    "#Printing actual labels from the raw data to compare with VGG19 predicted labels\n",
    "  #print(f'Actual Labels: {act_label}\\n\\n')\n",
    "  for i in act_label:     #One hot encoding of the labels\n",
    "      y_label[classes[i]]=1\n",
    "  labels.append(np.array(y_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4IPfpILgdRw"
   },
   "source": [
    "Converting and reshaping image/label data to make them compatible with VGG19 model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_grUESCGDr3"
   },
   "outputs": [],
   "source": [
    "data2=np.array(data)\n",
    "data2=data2.reshape(50,224,224,3)\n",
    "labels2=np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UG7N9ITiBSq"
   },
   "source": [
    "Printing number of data points for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4RLZYbpKyOU",
    "outputId": "8831582b-4ea0-4c6b-ff90-be87bee5b67b"
   },
   "outputs": [],
   "source": [
    "print(f'No of data points: {len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJOkwGkAio3H"
   },
   "source": [
    "Training the modified model to classify given dataset into 20 classes, with 80-20% test-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1qxgOamSqCdw",
    "outputId": "550e80bb-27a7-4cd2-980b-f0f3f68ba96e"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "model_hist=new_model.fit(\n",
    "    x=data2,\n",
    "    y=labels2,\n",
    "    batch_size=None,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[es],\n",
    "    validation_split=0.2,\n",
    "    validation_data=None,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=None,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDxmXxBqkEy2"
   },
   "source": [
    "Plotting training history to understand training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ub2EjZ2lj--X"
   },
   "outputs": [],
   "source": [
    "pyplot.plot(model_hist.history['loss'], label='train')\n",
    "pyplot.plot(model_hist.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzaZLjiYiu3o"
   },
   "source": [
    "Making predictions on the given image using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iLZjXrrKUH5"
   },
   "outputs": [],
   "source": [
    "  img = image.load_img('/content/drive/MyDrive/JPEGImages/xxxx.jpeg', target_size=(224, 224))\n",
    "  plt.imshow(img)\n",
    "  plt.axis('off')\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  res_new = new_model.predict(x)\n",
    "  for i in classes.keys():\n",
    "    if classes[i]==res_new.argmax():\n",
    "      print(f'This looks like a {i}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VGG19_VOC2012.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
